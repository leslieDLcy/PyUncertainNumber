{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T16:57:40.289983Z",
     "start_time": "2025-09-15T16:57:37.345465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils_bayesian import PriorUniform\n",
    "from mcmc import TMCMCCalibrator\n",
    "\n",
    "# --- Toy forward model & likelihood ---\n",
    "# y = θ1 + 0.5*θ2 + ε, ε ~ N(0, σ^2)\n",
    "sigma = 0.3\n",
    "def forward(theta):  # (n,2)->(n,)\n",
    "    theta = np.atleast_2d(theta)\n",
    "    return theta[:,0] + 0.5*theta[:,1]\n",
    "\n",
    "def loglik(samples, y_obs):  # vectorized\n",
    "    mu = forward(samples)\n",
    "    return -0.5*((y_obs - mu)/sigma)**2 - 0.5*np.log(2*np.pi*sigma**2)\n",
    "\n",
    "# --- Ground truth & observation ---\n",
    "theta_true = np.array([1.5, -0.5])\n",
    "y_obs = theta_true[0] + 0.5*theta_true[1] + sigma*np.random.randn()\n",
    "\n",
    "# --- Priors: θ ∈ [-5,5]^2 ---\n",
    "prior = PriorUniform(lb=np.array([-5., -5.]), ub=np.array([5., 5.]))\n",
    "\n",
    "# --- TMCMC calibration ---\n",
    "cal = TMCMCCalibrator(n_particles=3000, n_mcmc_steps=4, max_mcmc_steps=6,\n",
    "                      target_ess_frac=0.95, adapt_scale=True, store_trace=False)\n",
    "\n",
    "cal.setup(priors=[prior], log_likelihood=loglik)\n",
    "post = cal.calibrate(observations=y_obs)  # returns dict\n",
    "\n",
    "samples = post[\"samples\"]\n",
    "print(\"Posterior mean:\", samples.mean(axis=0))\n",
    "print(\"True θ:\", theta_true)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(samples[:,0], samples[:,1], s=3, alpha=0.25, label=\"TMCMC samples\")\n",
    "plt.scatter(theta_true[0], theta_true[1], c=\"r\", marker=\"x\", s=100, label=\"θ_true\")\n",
    "plt.xlabel(\"θ1\"); plt.ylabel(\"θ2\"); plt.grid(True); plt.legend()\n",
    "plt.title(\"TMCMC posterior (toy linear model)\")\n",
    "plt.show()\n"
   ],
   "id": "7d04f07aab184786",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3000,2) into shape (3000,)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     26\u001B[39m cal = TMCMCCalibrator(n_particles=\u001B[32m3000\u001B[39m, n_mcmc_steps=\u001B[32m4\u001B[39m, max_mcmc_steps=\u001B[32m6\u001B[39m,\n\u001B[32m     27\u001B[39m                       target_ess_frac=\u001B[32m0.95\u001B[39m, adapt_scale=\u001B[38;5;28;01mTrue\u001B[39;00m, store_trace=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     29\u001B[39m cal.setup(priors=[prior], log_likelihood=loglik)\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m post = \u001B[43mcal\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcalibrate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobservations\u001B[49m\u001B[43m=\u001B[49m\u001B[43my_obs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# returns dict\u001B[39;00m\n\u001B[32m     32\u001B[39m samples = post[\u001B[33m\"\u001B[39m\u001B[33msamples\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     33\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mPosterior mean:\u001B[39m\u001B[33m\"\u001B[39m, samples.mean(axis=\u001B[32m0\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\PyUncertainNumber\\src\\pyuncertainnumber\\calibration\\mcmc.py:71\u001B[39m, in \u001B[36mTMCMCCalibrator.calibrate\u001B[39m\u001B[34m(self, observations, resample_n)\u001B[39m\n\u001B[32m     69\u001B[39m N = \u001B[38;5;28mself\u001B[39m.n_particles\n\u001B[32m     70\u001B[39m \u001B[38;5;66;03m# Stage 0: prior population & likelihoods\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m71\u001B[39m Sm = \u001B[43minitial_population\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_priors\u001B[49m\u001B[43m)\u001B[49m      \u001B[38;5;66;03m# (N,D)\u001B[39;00m\n\u001B[32m     72\u001B[39m Lm = np.asarray(\u001B[38;5;28mself\u001B[39m._loglik(Sm, observations), \u001B[38;5;28mfloat\u001B[39m)  \u001B[38;5;66;03m# (N,)\u001B[39;00m\n\u001B[32m     73\u001B[39m beta, ESS, logZ = \u001B[32m0.0\u001B[39m, \u001B[38;5;28mfloat\u001B[39m(N), \u001B[32m0.0\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\GitHub\\PyUncertainNumber\\src\\pyuncertainnumber\\calibration\\utils_bayesian.py:300\u001B[39m, in \u001B[36minitial_population\u001B[39m\u001B[34m(N, all_pars)\u001B[39m\n\u001B[32m    298\u001B[39m ini_pop = np.zeros((N, \u001B[38;5;28mlen\u001B[39m(all_pars)))\n\u001B[32m    299\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(all_pars)):\n\u001B[32m--> \u001B[39m\u001B[32m300\u001B[39m     \u001B[43mini_pop\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m = all_pars[i].generate_rns(N)\n\u001B[32m    301\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m ini_pop\n",
      "\u001B[31mValueError\u001B[39m: could not broadcast input array from shape (3000,2) into shape (3000,)"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
